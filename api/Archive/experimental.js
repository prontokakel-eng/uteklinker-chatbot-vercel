// lib/experimental.js
import OpenAI from "openai";
import { containsAllowedWord, normalizeMessage } from "./../lib/utils.js";
import { findBestMatch } from "./faq.js";

const FAQ_THRESHOLD = 0.7;

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export async function chatHandlerExperimental(req, res) {
  try {
    const { message, lang = "SE", mode = "STRICT" } = req.body;
    if (!message || typeof message !== "string") {
      return res.status(400).json({ error: "Ogiltig fr√•ga" });
    }

    console.log("üì• /api/chat (experimental) kallad. Body:", req.body);
    console.log("üîé Match mode:", mode);

    // ‚úÖ Normalisera (utan synonymer)
    const normalizedMessage = normalizeMessage(message);
    console.log("‚úÖ normalizedMessage:", normalizedMessage);

    // 1) Validation
    if (!containsAllowedWord(normalizedMessage, lang)) {
      return res.json({
        reply:
          "Din fr√•ga √§r inte relaterad till v√•ra produkter, v√§nligen omformulera.",
        source: "Validation",
      });
    }

    // 2) FAQ Match
    const match = findBestMatch(normalizedMessage, lang);
    if (match && match.score >= FAQ_THRESHOLD) {
      return res.json({
        reply: match.match.answer || "‚ùå FAQ-svar saknas",
        source: `FAQ (${mode})`,
        score: match.score,
        normalizedMessage,
      });
    }

    // 3) AI Fallback
    const aiResponse = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        { role: "system", content: "Du √§r en hj√§lpsam kundsupportagent f√∂r byggprodukter." },
        { role: "user", content: normalizedMessage },
      ],
    });

    const reply = aiResponse.choices[0].message.content;
    return res.json({ reply, source: "AI", score: 0, normalizedMessage });
  } catch (err) {
    console.error("üí• Experimental handler error:", err);
    res.status(500).json({ error: "Server error" });
  }
}
